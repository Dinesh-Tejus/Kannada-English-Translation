{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d962c41-9c1b-4d98-8f03-36ca6a912d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b46f81-36f3-48fd-b5c2-c50fd1f2309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install indic_nlp_library==0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff41387e-5594-412a-b3d9-1742d9e1fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430d75b4-4f0e-4ac2-90c5-06d9f0221caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'nltk' from '/shared/centos7/anaconda3/2021.05/lib/python3.8/site-packages/nltk/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d422ee-c685-48d0-97b6-b19612715cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfdeefd-2328-4310-adb1-d83fcb17a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0f4c6d-5d16-49fc-924c-2de9a90c1fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87235b0c-7403-4b03-8694-c791b79ad1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10 # maximum length of sentences\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.lstm = nn.LSTM(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(0)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden[0].permute(1, 0, 2)  # For LSTM, hidden is a tuple (hidden_state, cell_state)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_lstm = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.lstm(input_lstm, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    \n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.source_sentences[index], self.target_sentences[index]\n",
    "\n",
    "\n",
    "def pad_sequence(sequence, pad_value):\n",
    "    # Padding function to add pad_value to sequences until they reach max_len\n",
    "    for i in range(MAX_LENGTH - len(sequence)):\n",
    "        sequence.append(pad_value)\n",
    "    return sequence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1faa47dd-df60-4ef0-ac89-a6e62d154219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb451c6d-f7ab-4495-b88c-a4e46f158ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get english tokens...: 100%|██████████| 4093524/4093524 [00:06<00:00, 588964.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Hes', 'a', 'scientist', '.', '</s>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get kannada tokens...: 100%|██████████| 4093524/4093524 [00:32<00:00, 126527.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'ಇವರು', 'ಸಂಶೋಧಕ', 'ಸ್ವಭಾವದವರು', '.', '</s>']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-20960aebb451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# kan_vocab = list(kan_vocab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkan_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "#DO NOT RUN THIS\n",
    "# get tokens from pre-processed files\n",
    "with open('eng_tokens.txt', 'r') as f:\n",
    "    tokens = f.readlines()\n",
    "eng_tokens = []\n",
    "for x in trange(len(tokens), desc='get english tokens...'):\n",
    "    eng_tokens.append(tokens[x].strip('\\n').split(' '))\n",
    "print(eng_tokens[0])\n",
    "\n",
    "with open('kan_tokens.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = f.readlines()\n",
    "kan_tokens = []\n",
    "for x in trange(len(tokens), desc='get kannada tokens...'):\n",
    "    kan_tokens.append(tokens[x].strip('\\n').split(' '))\n",
    "print(kan_tokens[0])\n",
    "\n",
    "# get vocabulary\n",
    "eng_vocab = dict()\n",
    "kan_vocab = dict()\n",
    "for i in eng_tokens:\n",
    "    for j in i:\n",
    "        eng_vocab[j] = None\n",
    "# eng_vocab = list(eng_vocab)\n",
    "\n",
    "for i in kan_tokens:\n",
    "    for j in i:\n",
    "        kan_vocab[j] = None\n",
    "# kan_vocab = list(kan_vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36f96bdb-a962-4f6b-ae89-64ac0422e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d68fd091-1584-4f40-954a-cd0f7721eace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "602f1d44-9265-4963-a6a1-af339ab2ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index lists\n",
    "eng_word2index = {word: index for index, word in enumerate(eng_vocab.keys())}\n",
    "kan_word2index = {word: index for index, word in enumerate(kan_vocab.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18d99ec3-d105-496e-adc8-19305c62d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(kan_word2index['</s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86620327-2ce9-4ee5-9198-cf206c514825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not run\n",
    "eng_indices = [[eng_word2index[word] for word in sent] for sent in eng_tokens] \n",
    "kan_indices = [[kan_word2index[word] for word in sent] for sent in kan_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de454e4-e87b-43fc-a66f-73ffbfcda381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8127f29-362f-4791-8f7d-96ca9396eba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bba9196f-c1f5-4606-8694-624a2297ba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093524\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4188b2db-36ab-4d06-862c-23971281a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate all sentences to length 40. or else the dataloader will not work\n",
    "# # eng_indices_padded = [pad_sequence(sent, eng_word2index['</s>']) if len(sent) <= MAX_LENGHT for sent in eng_indices]\n",
    "# eng_indices_padded = [pad_sequence(sent, eng_word2index['</s>']) if len(sent) <= MAX_LENGTH else None for sent in eng_indices]\n",
    "# eng_indices_padded = [sent for sent in eng_indices_padded if sent is not None]\n",
    "# kan_indices_padded = [pad_sequence(sent, kan_word2index['</s>']) if len(sent) <= MAX_LENGTH else None for sent in kan_indices]\n",
    "# kan_indices_padded = [sent for sent in kan_indices_padded if sent is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd8b98df-4bfe-4763-ae5a-b60f334c890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_indices_padded = []\n",
    "kan_indices_padded = []\n",
    "\n",
    "for eng_sent, kan_sent in zip(eng_tokens, kan_tokens):\n",
    "    if len(eng_sent) <= MAX_LENGTH and len(kan_sent) <= MAX_LENGTH:\n",
    "        eng_indices_padded.append(pad_sequence([eng_word2index[word] for word in eng_sent], eng_word2index['</s>']))\n",
    "        kan_indices_padded.append(pad_sequence([kan_word2index[word] for word in kan_sent], kan_word2index['</s>']))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "# Ensure that both lists have the same length\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4f16f9a-77f3-4fe4-a13b-76558c3cb976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Number of English sentences: 2143506, Number of Kannada sentences: 2143506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(eng_indices_padded) == len(kan_indices_padded), f\"Number of English sentences: {len(eng_indices_padded)}, Number of Kannada sentences: {len(kan_indices_padded)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "168921b3-c478-4470-b28f-5af9c5fdfa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2143506\n",
      "[0, 1, 2, 3, 4, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_indices_padded))\n",
    "print(eng_indices_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f23e75db-9dc3-4bf5-8480-e0a8537e00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_indices1 = eng_indices_padded[:20000] # change this for training more\n",
    "kan_indices1 = kan_indices_padded[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6884f-da80-46c0-9d5a-e2d0126b455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_word2index[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66762784-7be9-420f-b1fc-902650cb7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "kan_train, kan_test, eng_train, eng_test = train_test_split(kan_indices1, eng_indices1, test_size=0.3)\n",
    "\n",
    "# Create datasets and dataloaders for train and test sets\n",
    "train_dataset = TranslationDataset(kan_train, eng_train)\n",
    "test_dataset = TranslationDataset(kan_test, eng_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2783b81-38d7-42c1-96b9-245e766e0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd14d392-ba95-4854-bd12-a4d7a40df993",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 100\n",
    "hidden_size = 128\n",
    "encoder = EncoderRNN(input_size=len(kan_vocab), hidden_size=hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size=hidden_size, output_size=len(eng_vocab)).to(device)\n",
    "optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd118810-7991-488f-b263-5342fa06f889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-trained models loaded.\n",
      "training begin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 143.0367116034031:  28%|██▊       | 28/100 [15:46<41:06, 34.26s/it]  "
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.exists(\"encoder200k.pth\") and os.path.exists(\"decoder200k.pth\"):\n",
    "    encoder =  EncoderRNN(input_size=len(kan_vocab), hidden_size=hidden_size).to(device)\n",
    "    decoder = AttnDecoderRNN(hidden_size=hidden_size, output_size=len(eng_vocab)).to(device)\n",
    "\n",
    "    encoder.load_state_dict(torch.load(\"encoder_final200k.pth\"))\n",
    "    decoder.load_state_dict(torch.load(\"decoder_final200k.pth\"))\n",
    "    print(\"pre-trained models loaded.\")\n",
    "    \n",
    "    \n",
    "print(\"training begin.\")\n",
    "import time\n",
    "\n",
    "# Training loop\n",
    "MODEL_SAVE_INTERVAL = 100 # save the model every so oftens\n",
    "losses = [] # average loss per epoch\n",
    "bar = trange(epochs, desc=f'')\n",
    "for epoch in bar:\n",
    "    epoch_loss = 0\n",
    "    for i, (kan_batch,eng_batch) in enumerate(train_dataloader): # TO-DO - Need to pad the data\n",
    "        time_start = time.time()\n",
    "        eng_batch = torch.stack(eng_batch, dim=1)\n",
    "        kan_batch = torch.stack(kan_batch, dim=1)\n",
    "\n",
    "        eng_batch = eng_batch.to(device)\n",
    "        kan_batch = kan_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(kan_batch)\n",
    "        decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden, target_tensor=eng_batch)\n",
    "\n",
    "        loss = criterion(decoder_outputs.view(-1, len(eng_vocab)), eng_batch.view(-1))\n",
    "        epoch_loss += (loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % MODEL_SAVE_INTERVAL == 0:\n",
    "            torch.save(encoder.state_dict(), f\"encoder200k.pth\")\n",
    "            torch.save(decoder.state_dict(), f\"decoder200k.pth\")\n",
    "        \n",
    "#         print(f\"batch took {time.time()-time_start} sec\")\n",
    "    epoch_loss /= len(eng_batch)    \n",
    "    losses.append(epoch_loss)\n",
    "    bar.set_description(f'loss: {epoch_loss}')\n",
    "\n",
    "    if epoch % MODEL_SAVE_INTERVAL == 0:\n",
    "        torch.save(encoder.state_dict(), f\"encoder200k.pth\")\n",
    "        torch.save(decoder.state_dict(), f\"decoder200k.pth\")\n",
    "\n",
    "torch.save(encoder.state_dict(), f\"encoder_final200k.pth\")\n",
    "torch.save(decoder.state_dict(), f\"decoder_final200k.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5538fad-b46c-47a3-a666-8470a3747d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3430f2-b89d-4193-af7b-9de923c2a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"encoder200k.pth\") and os.path.exists(\"decoder200k.pth\"):\n",
    "    encoder =  EncoderRNN(input_size=len(kan_vocab), hidden_size=hidden_size).to(device)  # Replace YourEncoderModelClass with the actual class of your encoder model\n",
    "    decoder = AttnDecoderRNN(hidden_size=hidden_size, output_size=len(eng_vocab)).to(device)\n",
    "\n",
    "    encoder.load_state_dict(torch.load(\"encoder20k.pth\"))\n",
    "    decoder.load_state_dict(torch.load(\"decoder20k.pth\"))\n",
    "    print(\"pre-trained models loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d351d-4c7d-490c-9f30-74a4d2e3921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(input_sentence):\n",
    "    # Preprocess input sentence\n",
    "    input_sequence = indic_tokenize.trivial_tokenize(input_sentence)\n",
    "    input_sequence.insert(0,\"<s>\")\n",
    "    input_sequence.append(\"</s>\")\n",
    "    vector =  [kan_word2index[word] for word in input_sequence]\n",
    "    input_sequence = pad_sequence(vector, kan_word2index['</s>'])\n",
    " \n",
    "    print(torch.tensor(input_sequence))\n",
    "    encoder_outputs, encoder_hidden = encoder(torch.tensor(input_sequence, device=device).view(-1, 1))\n",
    "#     print(encoder_outputs)\n",
    "    decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden)\n",
    " \n",
    "    _, topi = decoder_outputs.topk(1) # return largest output of the tensor\n",
    "    decoded_ids = topi.squeeze()\n",
    "#     print(decoded_ids)\n",
    "\n",
    "    decoded_words = []\n",
    "    for idx in decoded_ids[0]:\n",
    "        if idx.item() == eng_word2index['</s>']:\n",
    "            decoded_words.append(eng_word2index['</s>'])\n",
    "            break\n",
    "        decoded_words.append(idx.item())\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00c95c-448e-4497-aaa1-062a4119c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = translate_sentence( 'ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು')\n",
    "output = \"\"\n",
    "for idx in out:\n",
    "    #print([key for key, val in eng_word2index.items() if val == idx])\n",
    "    output +=  [key for key, val in eng_word2index.items() if val == idx][0] + \" \"\n",
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084e1b8-b060-4dd4-80e9-a9d964947c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAcc(encoder, decoder, dataloader, reference_translations):\n",
    "    references = []\n",
    "    translations = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for kan_batch, eng_batch in tqdm(dataloader, desc='Evaluating'):\n",
    "            kan_batch = torch.stack(kan_batch, dim=1).to(device)\n",
    "            eng_batch = torch.stack(eng_batch, dim=1).to(device)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(kan_batch)\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor=eng_batch)\n",
    "\n",
    "            _, preds = decoder_outputs.max(2)\n",
    "\n",
    "            references.extend(eng_batch.cpu().numpy().tolist())\n",
    "            translations.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "            # Calculate accuracy\n",
    "            for pred_sent, ref_sent in zip(preds.cpu().numpy().tolist(), eng_batch.cpu().numpy().tolist()):\n",
    "                total_predictions += len(ref_sent)\n",
    "                for pred_token, ref_token in zip(pred_sent, ref_sent):\n",
    "                    if pred_token == ref_token:\n",
    "                        correct_predictions += 1\n",
    "    \n",
    "\n",
    "    bleu_score = corpus_bleu(references, translations)\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "  \n",
    "\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluateAcc(encoder, decoder, test_dataloader, eng_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c627084e-3f10-4a88-96be-6e4d77b96d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "177859",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b32a823c90ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluateBLEU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLEU Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-b32a823c90ae>\u001b[0m in \u001b[0;36mevaluateBLEU\u001b[0;34m(encoder, decoder, dataloader, reference_translations)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpred_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_sent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# Convert indices back to tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mpred_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meng_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_sent\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0meng_word2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mref_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meng_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mref_sent\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0meng_word2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-b32a823c90ae>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpred_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_sent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# Convert indices back to tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mpred_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meng_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_sent\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0meng_word2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mref_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meng_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mref_sent\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0meng_word2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 177859"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluateBLEU(encoder, decoder, dataloader, reference_translations):\n",
    "    references = []\n",
    "    translations = []\n",
    "    with torch.no_grad():\n",
    "        for kan_batch, eng_batch in tqdm(dataloader, desc='Evaluating'):\n",
    "            kan_batch = torch.stack(kan_batch, dim=1).to(device)\n",
    "            eng_batch = torch.stack(eng_batch, dim=1).to(device)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(kan_batch)\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor=eng_batch)\n",
    "\n",
    "            _, preds = decoder_outputs.max(2)\n",
    "\n",
    "            for pred_sent, ref_sent in zip(preds.cpu().numpy().tolist(), eng_batch.cpu().numpy().tolist()):\n",
    "                # Convert indices back to tokens\n",
    "                pred_tokens = [eng_vocab[token_idx] for token_idx in pred_sent if token_idx != eng_word2index['</s>']]\n",
    "                ref_tokens = [eng_vocab[token_idx] for token_idx in ref_sent if token_idx != eng_word2index['</s>']]\n",
    "                references.append([ref_tokens])\n",
    "                translations.append(pred_tokens)\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = corpus_bleu(references, translations)\n",
    "\n",
    "    return bleu_score\n",
    "\n",
    "# Evaluate the model\n",
    "bleu_score = evaluateBLEU(encoder, decoder, test_dataloader, eng_test)\n",
    "\n",
    "print(\"BLEU Score:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8094b4-428e-45f3-a391-871a4259073f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
